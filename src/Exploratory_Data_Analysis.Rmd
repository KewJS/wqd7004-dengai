---
title: "DengAI_EDA"
author: "Kew Jing Sheng"
date: "5/30/2022"
output: html_document
---

```{r setup, include=FALSE, , out.width="100%"}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pkgs <- c('tidyverse', 'corrplot', 'magrittr', 'zoo', 'RColorBrewer', 'gridExtra','MASS')
invisible(lapply(pkgs, require, character.only = T))
```

## Import Data

```{r import data}
train_features <- read.csv('./data/dengue_features_train.csv')
train_labels <- read.csv('./data/dengue_labels_train.csv')
test_features <- read.csv('./data/dengue_features_test.csv')

train_cleaned <- read.csv('./data/Train_cleaned.csv')
test_cleaned <- read.csv('./data/Test_cleaned.csv')
```

### Read data (Train)

Read in both before processing data (sj_train_features, iq_train_features) and after processing data (sj_clean_train, iq_clean_train). Outliers using IQR is performed on after processing data to remove outliers in 3 different columns, which are, 'reanalysis_sat_precip_amt_mm', 'reanalysis_precip_amt_kg_per_m2', 'station_precip_mm'
```{r split into sj & iq}
sj_train_features = train_features %>% filter(city == 'sj')
sj_train_features = sj_train_features %>% 
                      select_if(!names(.) %in% c('X'))
sj_train_labels   = train_labels   %>% filter(city == 'sj')
sj_train_labels = sj_train_labels %>% 
                    select_if(!names(.) %in% c('X'))
iq_train_features = train_features %>% filter(city == 'iq')
iq_train_features = iq_train_features %>% 
                      select_if(!names(.) %in% c('X'))
iq_train_labels   = train_labels   %>% filter(city == 'iq')
iq_train_labels = iq_train_labels %>% 
                    select_if(!names(.) %in% c('X'))

sj_clean_train = train_cleaned %>% filter(city == 'sj')
sj_clean_train[['week_start_date']] <- as.POSIXct(sj_clean_train[['week_start_date']],
                                                format = "%Y-%m-%d")
sj_clean_train = sj_clean_train %>% 
  dplyr::filter(reanalysis_sat_precip_amt_mm > quantile(reanalysis_sat_precip_amt_mm, 0.25), 
                reanalysis_sat_precip_amt_mm < quantile(reanalysis_sat_precip_amt_mm, 0.75))
sj_clean_train = sj_clean_train %>% 
  dplyr::filter(reanalysis_precip_amt_kg_per_m2 > quantile(reanalysis_precip_amt_kg_per_m2, 0.25), 
                reanalysis_precip_amt_kg_per_m2 < quantile(reanalysis_precip_amt_kg_per_m2, 0.75))
sj_clean_train = sj_clean_train %>% 
  dplyr::filter(station_precip_mm > quantile(station_precip_mm, 0.25), 
                station_precip_mm < quantile(station_precip_mm, 0.75))

iq_clean_train = train_cleaned %>% filter(city == 'iq')
iq_clean_train[['week_start_date']] <- as.POSIXct(iq_clean_train[['week_start_date']],
                                                  format = "%Y-%m-%d")
```

## Missing Values Visualization

From processing steps, missing values are imputed using KNN model in columns like ndvi_ne, ndvi_nw & ndvi_sw. We can see from the vertical bar plot, after imputation, missing values are imputed. Imputation are performed in 2 different cities, 'sj' and 'iq'.

```{r sj missing values visualization}
apply(sj_train_features, 2, function(x) 
  round(100 * (length(which(is.na(x))))/length(x) , digits = 1)) %>%
  as.data.frame() %>%
  `names<-`('Percent of Missing Values')

sj_train_features  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()

apply(sj_clean_train, 2, function(x) 
  round(100 * (length(which(is.na(x))))/length(x) , digits = 1)) %>%
  as.data.frame() %>%
  `names<-`('Percent of Missing Values')

sj_clean_train  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()
```
## Outliers Visualization

For columns 'reanalysis_sat_precip_amt_mm', 'reanalysis_precip_amt_kg_per_m2' & 'station_precip_mm', we can see the outliers are present but after using IQR-filtering to remove the outliers, we can see that the outliers are removed, as shown in boxplot below. Same as missing values visualization, outliers removal are done in 2 different cities, which are 'sj' & 'iq'.

```{r}
box_plot_after_ol_removed <- ggplot(sj_train_features, aes(y = reanalysis_sat_precip_amt_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'reanalysis_sat_precip_amt_mm'")

box_plot_after_ol_removed <- ggplot(sj_clean_train, aes(y = reanalysis_sat_precip_amt_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'reanalysis_sat_precip_amt_mm'")

box_plot_after_ol_removed <- ggplot(sj_train_features, aes(y = reanalysis_precip_amt_kg_per_m2))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'reanalysis_precip_amt_kg_per_m2'")

box_plot_after_ol_removed <- ggplot(sj_clean_train, aes(y = reanalysis_precip_amt_kg_per_m2))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'reanalysis_precip_amt_kg_per_m2'")

box_plot_after_ol_removed <- ggplot(sj_train_features, aes(y = station_precip_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'station_precip_mm'")

box_plot_after_ol_removed <- ggplot(sj_clean_train, aes(y = station_precip_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'station_precip_mm'")
```

```{r iq missing values visualization}
apply(iq_train_features, 2, function(x) 
  round(100 * (length(which(is.na(x))))/length(x) , digits = 1)) %>%
  as.data.frame() %>%
  `names<-`('Percent of Missing Values')

iq_train_features  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()

apply(iq_clean_train, 2, function(x) 
  round(100 * (length(which(is.na(x))))/length(x) , digits = 1)) %>%
  as.data.frame() %>%
  `names<-`('Percent of Missing Values')

iq_clean_train  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()
```
```{r}
box_plot_after_ol_removed <- ggplot(iq_train_features, aes(y = reanalysis_sat_precip_amt_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'reanalysis_sat_precip_amt_mm'")

box_plot_after_ol_removed <- ggplot(iq_clean_train, aes(y = reanalysis_sat_precip_amt_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'reanalysis_sat_precip_amt_mm'")

box_plot_after_ol_removed <- ggplot(iq_train_features, aes(y = reanalysis_precip_amt_kg_per_m2))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'reanalysis_precip_amt_kg_per_m2'")

box_plot_after_ol_removed <- ggplot(iq_clean_train, aes(y = reanalysis_precip_amt_kg_per_m2))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'reanalysis_precip_amt_kg_per_m2'")

box_plot_after_ol_removed <- ggplot(iq_train_features, aes(y = station_precip_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of Before Outliers Removal of 'station_precip_mm'")

box_plot_after_ol_removed <- ggplot(iq_clean_train, aes(y = station_precip_mm))
box_plot_after_ol_removed +
  geom_boxplot() +coord_flip()+ggtitle("Boxplot of After Outliers Removal of 'station_precip_mm'")
```
## Understanding 'sj' & 'iq' Data Acquired Based on Data Quantity

We can see that 'sj' city has more data than 'iq'.

```{r data shape for each city}
cat('\nSan Juan\n',
    '\t features: ', sj_train_features %>% ncol, 
    '\t entries: ' , sj_train_features %>% nrow,
    '\t labels: '  , sj_train_labels %>% nrow)

cat('\nIquitos\n',
    '\t features: ', iq_train_features %>% ncol, 
    '\t entries: ' , iq_train_features %>% nrow,
    '\t labels: '  , iq_train_labels %>% nrow)
```
## Target Variable: 'total_cases'

Besides from input data quantity difference between 'sj' & 'iq' data, we can see that the data distribution of target variable between 2 cities are also differnt. Hence, modelling will be done based on 2 different cities. 

```{r}
cat('\nSan Juan\n',
    '\t total cases mean: ',      sj_train_labels$total_cases %>% mean(), 
    '\t total cases variance: ' , sj_train_labels$total_cases %>% var() )

cat('\nIquitos\n',
    '\t total cases mean: ',      iq_train_labels$total_cases %>% mean(), 
    '\t total cases variance: ' , iq_train_labels$total_cases %>% var() )
```
## Target Variable: 'total_cases' Period

We can see that 'iq' target variable data ranged from 2000 - 2010, which is contrast to 'sj' where the data is ranged from 1990 to 2010.

```{r}
train_cleaned %>% ggplot() + 
  geom_boxplot(aes(year, total_cases, group=year)) + 
  facet_grid(city ~ ., scale = "free") + 
  ggtitle("Total number of cases per year in each cities")
```
## Target Variable: 'total_cases' Distribution

Although statistical information and period of 'total_cases' in 2 different cities are different, however, the distribution of the data are similar across 2 different cities. Although the distribution size across 2 different cities are similar, the nature of data acquired have different maximum values where we can see 'sj' data has higher range of data across 0 - 500.

```{r}
rbind(iq_train_labels, sj_train_labels) %>% 
  ggplot(aes(x = total_cases,fill = ..count..)) + 
  geom_histogram(bins = 12, colour = 'black') + ggtitle('Total Cases of Dengue') +
  scale_y_continuous(breaks = seq(0,700,100)) + facet_wrap(~city)
```
## Creating Correlation Plot of 'sj' City

We can see that from all the input features, they do not have high correlation, either positive or negative with target variable, 'total_cases', as we see the correlation value does not go over 50%.

```{r sj correlation analysis}
sj_clean_train %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="color",
           col=brewer.pal(n=8, name="RdBu"), tl.cex=0.7, tl.offset=2)
```
## Creating Correlation Plot of 'iq' City

Same goes to 'iq' city, We can see that from all the input features, they do not have high correlation, either positive or negative with target variable, 'total_cases', as we see the correlation value does not go over 50%.

```{r iq correlation analysis}

iq_clean_train %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M2

corrplot(M2, type="lower", method="color",
           col=brewer.pal(n=8, name="RdBu"), tl.cex=0.7, tl.offset=2)
```
## Creating Correlation Barplot of 2 Cities, on 'sj' & 'iq'

Even though the target variable, 'total_cases' in both cities have same distribution, however, they have different highest correlated features. This may due to data statistical different between 2 cities. In 'sj' city, the most positive relation feature with 'total_cases' are 'station_min_temp_c' & 'station_avg_temp_c', while the highest negative correlated feature would be 'ndvi_ne'. In contrast, in 'iq' city, the most positive relation feature with 'total_cases' are 'reanalysis_specific_humidity_g_per_kg' & 'reanalysis_dew_point_temp_k', while the highest negative correlated feature would be 'reanalysis_tdtr_k'. All these highest positive and negative correlated features do not have relationship over 50%.

```{r, out.width="50%"}
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.15,.25)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
sort(M2[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.15,.25)) +
  labs(title = 'Iquitos\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor2

grid.arrange(cor1, cor2, nrow = 1)
```
## Creating Line Plot to Understand the Highest Correlated Features to 'total_cases' in 'sj'

Now we can see that the data are not correlated well with 'total_cases' across time. This may due to the scale between the data or, the data are not highly correlated. Scaling is suggested for modelling stage later on the input features to match the data distribution.

```{r}
ggplot()+
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, station_min_temp_c), color='blue') + 
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")

ggplot()+
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, station_avg_temp_c), color='blue') + 
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")

ggplot()+
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, reanalysis_specific_humidity_g_per_kg), color='blue') + 
  geom_line(data=sj_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")
```
## Creating Line Plot to Understand the Highest Correlated Features to 'total_cases' in iq'

Now we can see that the data are not correlated well with 'total_cases' across time. This may due to the scale between the data or, the data are not highly correlated. Scaling is suggested for modelling stage later on the input features to match the data distribution.

```{r}
ggplot()+
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, reanalysis_specific_humidity_g_per_kg), color='blue') + 
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")

ggplot()+
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, reanalysis_dew_point_temp_k), color='blue') + 
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")

ggplot()+
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, reanalysis_tdtr_k), color='blue') + 
  geom_line(data=iq_clean_train, mapping=aes(week_start_date, total_cases), color='red') + 
  ggtitle("Reanalysis_Specific_Humidity_g_per_kg vs Total_Cases over Time")
```
